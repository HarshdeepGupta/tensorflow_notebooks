{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some variables , so that the code is maintainable\n",
    "num_datapoints = 1000\n",
    "batch_size = 5\n",
    "steps = 1000\n",
    "test_W = 2\n",
    "test_bias = 5\n",
    "learn_rate = 0.000001\n",
    "log_dir = \"/logs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "# Y = X*W+b\n",
    "X = tf.placeholder(tf.float32,[None, 1], name=\"Data_matrix_row\")\n",
    "W = tf.Variable(tf.zeros([1,1]), name=\"Weight_matrix\")\n",
    "b = tf.Variable(tf.zeros([1]), name = \"biases\")\n",
    "Y = tf.placeholder(tf.float32,[None, 1], name = \"targets\")\n",
    "\n",
    "with tf.name_scope(\"Linear_Model\") as scope:\n",
    "    prediction = tf.matmul(X,W) + b\n",
    "#     define the cost function, SSE\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(tf.square(prediction - Y))\n",
    "# train using gradient descent\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)\n",
    "\n",
    "# TODO: add summary operations\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# prepare the fake data matrix\n",
    "data = []\n",
    "targets = []\n",
    "for i in xrange(num_datapoints):\n",
    "#     the model is y = WX + b, W is test_W and b is test_bias\n",
    "    data.append([i])\n",
    "    targets.append([test_W*i + test_bias])\n",
    "# data = np.transpose(data)\n",
    "\n",
    "print(np.shape(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 iteration:\n",
      "W: 0.000044\n",
      "b: 0.000018\n",
      "After 100 iteration:\n",
      "W: 2.010037\n",
      "b: 0.014156\n",
      "After 200 iteration:\n",
      "W: 2.005102\n",
      "b: 0.014168\n",
      "After 300 iteration:\n",
      "W: 2.009932\n",
      "b: 0.014363\n",
      "After 400 iteration:\n",
      "W: 2.005220\n",
      "b: 0.014386\n",
      "After 500 iteration:\n",
      "W: 2.009830\n",
      "b: 0.014571\n",
      "After 600 iteration:\n",
      "W: 2.005387\n",
      "b: 0.014603\n",
      "After 700 iteration:\n",
      "W: 2.009729\n",
      "b: 0.014779\n",
      "After 800 iteration:\n",
      "W: 2.005601\n",
      "b: 0.014821\n",
      "After 900 iteration:\n",
      "W: 2.009631\n",
      "b: 0.014986\n"
     ]
    }
   ],
   "source": [
    "# training with mini batch gradient descent\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    batch_start_idx = 0\n",
    "    for i in range(steps):\n",
    "#         prepare the batch\n",
    "        batch_start_idx = (i * batch_size) % (num_datapoints - batch_size)\n",
    "        batch_end_idx = batch_start_idx + batch_size\n",
    "        batch_xs = data[batch_start_idx:batch_end_idx]\n",
    "        batch_ys = targets[batch_start_idx:batch_end_idx]\n",
    "        xs = np.array(batch_xs)\n",
    "        ys = np.array(batch_ys)\n",
    "        \n",
    "        feed_dict = { X: xs, Y: ys }\n",
    "        sess.run(train_step, feed_dict=feed_dict)\n",
    "        if i%100 == 0:\n",
    "            print(\"After %d iteration:\" % i)\n",
    "            print(\"W: %f\" % sess.run(W))\n",
    "            print(\"b: %f\" % sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
