{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define some variables , so that the code is maintainable\n",
    "num_datapoints = 1000\n",
    "batch_size = 100\n",
    "steps = 10000\n",
    "test_W = 2\n",
    "test_bias = 5\n",
    "learn_rate = 0.1\n",
    "log_dir = \"logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear regression model\n",
    "# Y = X*W+b\n",
    "X = tf.placeholder(tf.float32,[None, 1], name=\"Data_matrix_row\")\n",
    "W = tf.Variable(tf.zeros([1,1]), name=\"Weight_matrix\")\n",
    "b = tf.Variable(tf.zeros([1]), name = \"biases\")\n",
    "Y = tf.placeholder(tf.float32,[None, 1], name = \"targets\")\n",
    "\n",
    "with tf.name_scope(\"Linear_Model\") as scope:\n",
    "    prediction = tf.matmul(X,W) + b\n",
    "#     define the cost function, SSE\n",
    "with tf.name_scope(\"cost\") as scope:\n",
    "    cost = tf.reduce_mean(tf.square(prediction - Y))\n",
    "# train using gradient descent\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.AdamOptimizer(learn_rate).minimize(cost)\n",
    "\n",
    "# add summary operations\n",
    "w_c = tf.summary.scalar(\"cost_function\", cost)\n",
    "# Merge all the summaries and write them out to log_dir\n",
    "merged = tf.summary.merge_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare the fake data matrix\n",
    "data = []\n",
    "targets = []\n",
    "for i in xrange(num_datapoints):\n",
    "#     the model is y = WX + b, W is test_W and b is test_bias\n",
    "    data.append([i])\n",
    "    targets.append([test_W*i + test_bias])\n",
    "# print(np.shape(data))\n",
    "\n",
    "\n",
    "def get_data(train = True, index = 0):\n",
    "    if train:\n",
    "        i = index\n",
    "        batch_start_idx = (i * batch_size) % (num_datapoints - batch_size)\n",
    "        batch_end_idx = batch_start_idx + batch_size\n",
    "        batch_xs = data[batch_start_idx:batch_end_idx]\n",
    "        batch_ys = targets[batch_start_idx:batch_end_idx]\n",
    "        xs = np.array(batch_xs)\n",
    "        ys = np.array(batch_ys)\n",
    "        return { X: xs, Y: ys }\n",
    "    else:\n",
    "        xs = np.array(data)\n",
    "        ys = np.array(targets)\n",
    "        return { X: xs, Y: ys }\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 iteration:\n",
      "W: 0.100000\n",
      "b: 0.100000\n",
      "After 1000 iteration:\n",
      "W: 2.003254\n",
      "b: 2.833416\n",
      "After 2000 iteration:\n",
      "W: 2.004937\n",
      "b: 3.780910\n",
      "After 3000 iteration:\n",
      "W: 1.514683\n",
      "b: 3.778207\n",
      "After 4000 iteration:\n",
      "W: 2.003098\n",
      "b: 4.616833\n",
      "After 5000 iteration:\n",
      "W: 2.000386\n",
      "b: 4.780690\n",
      "After 6000 iteration:\n",
      "W: 2.000217\n",
      "b: 4.876739\n",
      "After 7000 iteration:\n",
      "W: 2.000114\n",
      "b: 4.933920\n",
      "After 8000 iteration:\n",
      "W: 2.000543\n",
      "b: 4.967046\n",
      "After 9000 iteration:\n",
      "W: 2.011467\n",
      "b: 4.997895\n"
     ]
    }
   ],
   "source": [
    "# training with mini batch gradient descent\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(log_dir,sess.graph)\n",
    "    for i in range(steps):\n",
    "        sess.run(train_step, feed_dict=get_data(True, i))\n",
    "        summary = sess.run(merged, feed_dict=get_data(False))\n",
    "        # write log\n",
    "        writer.add_summary(summary,  i)\n",
    "        if i%1000 == 0:\n",
    "            print(\"After %d iteration:\" % i)\n",
    "            print(\"W: %f\" % sess.run(W))\n",
    "            print(\"b: %f\" % sess.run(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
